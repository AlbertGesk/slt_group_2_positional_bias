{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-13T16:49:20.337429Z",
     "start_time": "2025-08-13T16:49:14.105470Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from dotenv.parser import Position\n",
    "\n",
    "from slt_positional_bias.dataset import generate_merged_data_frame, sort_data_frame, store_df_as_parquet, load_parquet_as_df, normalize_and_tokenize, jaccard, spearman_word_order_correlation\n",
    "\n",
    "from slt_positional_bias.plots import savetable, plot_spearman_dict, export_table_txt\n",
    "from slt_positional_bias.features import sacrebleu_corpus, rouge_corpus, meteor_corpus, bertscore_corpus\n",
    "\n",
    "df_10_name = \"reference-based-df_10-1-2025-08-13 14h-15m-51s\"\n",
    "df_20_name = \"reference-based-df_20-1-2025-08-13 14h-15m-51s\"\n",
    "df_30_name = \"reference-based-df_30-1-2025-08-13 14h-15m-51s\"\n",
    "df_40_name = \"reference-based-df_40-1-2025-08-13 14h-15m-51s\"\n",
    "\n",
    "df_10 = load_parquet_as_df(df_10_name)\n",
    "df_20 = load_parquet_as_df(df_20_name)\n",
    "df_30 = load_parquet_as_df(df_30_name)\n",
    "df_40 = load_parquet_as_df(df_40_name)\n",
    "\n",
    "df_10"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-08-13 18:49:14.140\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mslt_positional_bias.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: C:\\Users\\Albert\\Documents\\SLT\\slt_group_2_positional_bias\u001B[0m\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Albert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Albert\\Documents\\SLT\\slt_group_2_positional_bias\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source '<Buffer>': Parquet file size is 0 bytes",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mArrowInvalid\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m     11\u001B[39m df_30_name = \u001B[33m\"\u001B[39m\u001B[33mreference-based-df_30-1-2025-08-13 14h-15m-51s\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     12\u001B[39m df_40_name = \u001B[33m\"\u001B[39m\u001B[33mreference-based-df_40-1-2025-08-13 14h-15m-51s\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m df_10 = \u001B[43mload_parquet_as_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_10_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     15\u001B[39m df_20 = load_parquet_as_df(df_20_name)\n\u001B[32m     16\u001B[39m df_30 = load_parquet_as_df(df_30_name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\SLT\\slt_group_2_positional_bias\\slt_positional_bias\\dataset.py:142\u001B[39m, in \u001B[36mload_parquet_as_df\u001B[39m\u001B[34m(file_name)\u001B[39m\n\u001B[32m    140\u001B[39m f_path = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mdata/processed/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.parquet\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    141\u001B[39m f_path_from_dir = SCRIPT_DIR / f_path\n\u001B[32m--> \u001B[39m\u001B[32m142\u001B[39m df = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_parquet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf_path_from_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    144\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\SLT\\slt_group_2_positional_bias\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:669\u001B[39m, in \u001B[36mread_parquet\u001B[39m\u001B[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001B[39m\n\u001B[32m    666\u001B[39m     use_nullable_dtypes = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    667\u001B[39m check_dtype_backend(dtype_backend)\n\u001B[32m--> \u001B[39m\u001B[32m669\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimpl\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    670\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    671\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    672\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    673\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    674\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    675\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    676\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    677\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    678\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\SLT\\slt_group_2_positional_bias\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:265\u001B[39m, in \u001B[36mPyArrowImpl.read\u001B[39m\u001B[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001B[39m\n\u001B[32m    258\u001B[39m path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001B[32m    259\u001B[39m     path,\n\u001B[32m    260\u001B[39m     filesystem,\n\u001B[32m    261\u001B[39m     storage_options=storage_options,\n\u001B[32m    262\u001B[39m     mode=\u001B[33m\"\u001B[39m\u001B[33mrb\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    263\u001B[39m )\n\u001B[32m    264\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m265\u001B[39m     pa_table = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapi\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparquet\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    266\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpath_or_handle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    267\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    268\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    269\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    270\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    271\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    273\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m catch_warnings():\n\u001B[32m    274\u001B[39m         filterwarnings(\n\u001B[32m    275\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    276\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mmake_block is deprecated\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    277\u001B[39m             \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m,\n\u001B[32m    278\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\SLT\\slt_group_2_positional_bias\\.venv\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1774\u001B[39m, in \u001B[36mread_table\u001B[39m\u001B[34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001B[39m\n\u001B[32m   1764\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mread_table\u001B[39m(source, *, columns=\u001B[38;5;28;01mNone\u001B[39;00m, use_threads=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m   1765\u001B[39m                schema=\u001B[38;5;28;01mNone\u001B[39;00m, use_pandas_metadata=\u001B[38;5;28;01mFalse\u001B[39;00m, read_dictionary=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1766\u001B[39m                memory_map=\u001B[38;5;28;01mFalse\u001B[39;00m, buffer_size=\u001B[32m0\u001B[39m, partitioning=\u001B[33m\"\u001B[39m\u001B[33mhive\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1770\u001B[39m                thrift_container_size_limit=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1771\u001B[39m                page_checksum_verification=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1774\u001B[39m         dataset = \u001B[43mParquetDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1775\u001B[39m \u001B[43m            \u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1776\u001B[39m \u001B[43m            \u001B[49m\u001B[43mschema\u001B[49m\u001B[43m=\u001B[49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1777\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1778\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpartitioning\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpartitioning\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1779\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1780\u001B[39m \u001B[43m            \u001B[49m\u001B[43mread_dictionary\u001B[49m\u001B[43m=\u001B[49m\u001B[43mread_dictionary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1781\u001B[39m \u001B[43m            \u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1782\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1783\u001B[39m \u001B[43m            \u001B[49m\u001B[43mignore_prefixes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_prefixes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1784\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpre_buffer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpre_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1785\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcoerce_int96_timestamp_unit\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcoerce_int96_timestamp_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1786\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdecryption_properties\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecryption_properties\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1787\u001B[39m \u001B[43m            \u001B[49m\u001B[43mthrift_string_size_limit\u001B[49m\u001B[43m=\u001B[49m\u001B[43mthrift_string_size_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1788\u001B[39m \u001B[43m            \u001B[49m\u001B[43mthrift_container_size_limit\u001B[49m\u001B[43m=\u001B[49m\u001B[43mthrift_container_size_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1789\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpage_checksum_verification\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpage_checksum_verification\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1790\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1791\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[32m   1792\u001B[39m         \u001B[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001B[39;00m\n\u001B[32m   1793\u001B[39m         \u001B[38;5;66;03m# module is not available\u001B[39;00m\n\u001B[32m   1794\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m filters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\SLT\\slt_group_2_positional_bias\\.venv\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1350\u001B[39m, in \u001B[36mParquetDataset.__init__\u001B[39m\u001B[34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001B[39m\n\u001B[32m   1346\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m single_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1347\u001B[39m     fragment = parquet_format.make_fragment(single_file, filesystem)\n\u001B[32m   1349\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset = ds.FileSystemDataset(\n\u001B[32m-> \u001B[39m\u001B[32m1350\u001B[39m         [fragment], schema=schema \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mfragment\u001B[49m\u001B[43m.\u001B[49m\u001B[43mphysical_schema\u001B[49m,\n\u001B[32m   1351\u001B[39m         \u001B[38;5;28mformat\u001B[39m=parquet_format,\n\u001B[32m   1352\u001B[39m         filesystem=fragment.filesystem\n\u001B[32m   1353\u001B[39m     )\n\u001B[32m   1354\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m   1356\u001B[39m \u001B[38;5;66;03m# check partitioning to enable dictionary encoding\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\SLT\\slt_group_2_positional_bias\\.venv\\Lib\\site-packages\\pyarrow\\_dataset.pyx:1473\u001B[39m, in \u001B[36mpyarrow._dataset.Fragment.physical_schema.__get__\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\SLT\\slt_group_2_positional_bias\\.venv\\Lib\\site-packages\\pyarrow\\error.pxi:155\u001B[39m, in \u001B[36mpyarrow.lib.pyarrow_internal_check_status\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\SLT\\slt_group_2_positional_bias\\.venv\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001B[39m, in \u001B[36mpyarrow.lib.check_status\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mArrowInvalid\u001B[39m: Could not open Parquet input source '<Buffer>': Parquet file size is 0 bytes"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dfs = {'df_10': df_10, 'df_20':df_20, 'df_30':df_30, 'df_40':df_40}\n",
    "dfs_jaccard = {}\n",
    "dfs_spearman = {}\n",
    "dfs_bleu = {}\n",
    "dfs_rouge = {}\n",
    "dfs_meteor = {}\n",
    "dfs_berts = {}\n",
    "\n",
    "for name, d in dfs.items():\n",
    "    df_jaccard = d.groupby('Position of Oracle')[['Jaccard Coefficient']].mean().reset_index()\n",
    "    df_spearman = d.groupby('Position of Oracle')[['Spearman Correlation Coefficient', 'Spearman p-value']].mean()\n",
    "    df_bleu = d.groupby('Position of Oracle')[['SacreBLEU']].mean()\n",
    "    df_rouge = d.groupby('Position of Oracle')[['ROUGE_1', 'ROUGE_2', 'ROUGE_L', 'ROUGE_Lsum']].mean()\n",
    "    df_meteor = d.groupby('Position of Oracle')[['METEOR']].mean()\n",
    "    df_berts = d.groupby('Position of Oracle')[['BERTScore-Precision', 'BERTScore-Recall', 'BERTScore-F1']].mean()\n",
    "\n",
    "    dfs_jaccard[f'{name}_jaccard'] = df_jaccard\n",
    "    dfs_spearman[f'{name}_spearman'] = df_spearman\n",
    "    dfs_bleu[f'{name}_bleu'] = df_bleu\n",
    "    dfs_rouge[f'{name}_rouge'] = df_rouge\n",
    "    dfs_meteor[f'{name}_meteor'] = df_meteor\n",
    "    dfs_berts[f'{name}_berts'] = df_berts\n",
    " \n",
    "dfs_berts"
   ],
   "id": "f2eb153aa6ef3b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dfs in [dfs_jaccard, dfs_spearman, dfs_bleu, dfs_rouge, dfs_meteor, dfs_berts]:\n",
    "    for name, d in dfs.items():\n",
    "        if dfs == dfs_jaccard:\n",
    "            export_table_txt(d, \"Jaccard Coefficient\", f\"{name}\")\n",
    "        if dfs == dfs_spearman:\n",
    "            export_table_txt(d, \"Spearman Correlation Coefficient\", f\"{name}\")\n",
    "        if dfs == dfs_bleu:\n",
    "            export_table_txt(d, \"SacreBLEU\", f\"{name}\")\n",
    "        if dfs == dfs_rouge:\n",
    "            export_table_txt(d, \"ROUGE\", f\"{name}\")\n",
    "        if dfs == dfs_meteor:\n",
    "            export_table_txt(d, \"METEOR\", f\"{name}\")\n",
    "        if dfs == dfs_berts:\n",
    "            export_table_txt(d, \"BERTScore\", f\"{name}\")                        \n"
   ],
   "id": "9dc2543a6dee78b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
