{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c91305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-09 18:03:59.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mslt_positional_bias.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\marti\\slt_group_2_positional_bias\u001b[0m\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-09 18:04:02.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mslt_positional_bias.dataset\u001b[0m:\u001b[36mgenerate_data_frame\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mfile path exists\u001b[0m\n",
      "\u001b[32m2025-08-09 18:04:08.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mslt_positional_bias.dataset\u001b[0m:\u001b[36mgenerate_data_frame\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mfile path exists\u001b[0m\n",
      "\u001b[32m2025-08-09 18:04:08.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mslt_positional_bias.dataset\u001b[0m:\u001b[36mgenerate_data_frame\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mfile path exists\u001b[0m\n",
      "\u001b[32m2025-08-09 18:04:08.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mslt_positional_bias.dataset\u001b[0m:\u001b[36mgenerate_merged_data_frame\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mdf column 'doc_id' is unique: True\u001b[0m\n",
      "\u001b[32m2025-08-09 18:04:08.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mslt_positional_bias.dataset\u001b[0m:\u001b[36mgenerate_merged_data_frame\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mdf contains NaN: False\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\slt_group_2_positional_bias\\slt_positional_bias\\dataset.py:74: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_filtered_rel = grouped.apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>rel_scoring</th>\n",
       "      <th>topic</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-105741</td>\n",
       "      <td>msmarco_v2.1_doc_56_1565054098#14_3191674270</td>\n",
       "      <td>0</td>\n",
       "      <td>is it dangerous to have wbc over 15,000 withou...</td>\n",
       "      <td>Hydrocodone Withdrawal: Symptoms, Timeline, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-105741</td>\n",
       "      <td>msmarco_v2.1_doc_16_287012450#4_490828734</td>\n",
       "      <td>0</td>\n",
       "      <td>is it dangerous to have wbc over 15,000 withou...</td>\n",
       "      <td>Bacteremia Treatment &amp; Management: Medical Car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-105741</td>\n",
       "      <td>msmarco_v2.1_doc_18_512963387#3_575791642</td>\n",
       "      <td>0</td>\n",
       "      <td>is it dangerous to have wbc over 15,000 withou...</td>\n",
       "      <td>Neonatal sepsis - Wikipedia Neonatal sepsis\\nN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-105741</td>\n",
       "      <td>msmarco_v2.1_doc_13_1071259551#11_2377754462</td>\n",
       "      <td>0</td>\n",
       "      <td>is it dangerous to have wbc over 15,000 withou...</td>\n",
       "      <td>Cause of Low and High White Blood Cell Count i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-105741</td>\n",
       "      <td>msmarco_v2.1_doc_39_1162159389#10_2348941613</td>\n",
       "      <td>0</td>\n",
       "      <td>is it dangerous to have wbc over 15,000 withou...</td>\n",
       "      <td>Treatment Options Post CLL Diagnosis | Everyda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>2024-96063</td>\n",
       "      <td>msmarco_v2.1_doc_25_947435380#15_1757291433</td>\n",
       "      <td>0</td>\n",
       "      <td>how using maps can impact your pedagogy</td>\n",
       "      <td>Intersectional Pedagogy | Denver Intersectiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>2024-96063</td>\n",
       "      <td>msmarco_v2.1_doc_30_727526048#13_1657957899</td>\n",
       "      <td>0</td>\n",
       "      <td>how using maps can impact your pedagogy</td>\n",
       "      <td>Pedagogy: What Educators Need to Know [Plus: 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>2024-96063</td>\n",
       "      <td>msmarco_v2.1_doc_42_303001194#16_566169799</td>\n",
       "      <td>0</td>\n",
       "      <td>how using maps can impact your pedagogy</td>\n",
       "      <td>The Measures of Academic Progress (MAP) Inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>2024-96063</td>\n",
       "      <td>msmarco_v2.1_doc_25_785358561#0_1506541701</td>\n",
       "      <td>0</td>\n",
       "      <td>how using maps can impact your pedagogy</td>\n",
       "      <td>Putting Pedagogy Principles to Use in Your Cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>2024-96063</td>\n",
       "      <td>msmarco_v2.1_doc_52_1260126505#8_2526623662</td>\n",
       "      <td>3</td>\n",
       "      <td>how using maps can impact your pedagogy</td>\n",
       "      <td>Maps and Map Learning in Social Studies\\nRes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic_id                                        doc_id  rel_scoring  \\\n",
       "0     2024-105741  msmarco_v2.1_doc_56_1565054098#14_3191674270            0   \n",
       "1     2024-105741     msmarco_v2.1_doc_16_287012450#4_490828734            0   \n",
       "2     2024-105741     msmarco_v2.1_doc_18_512963387#3_575791642            0   \n",
       "3     2024-105741  msmarco_v2.1_doc_13_1071259551#11_2377754462            0   \n",
       "4     2024-105741  msmarco_v2.1_doc_39_1162159389#10_2348941613            0   \n",
       "...           ...                                           ...          ...   \n",
       "2235   2024-96063   msmarco_v2.1_doc_25_947435380#15_1757291433            0   \n",
       "2236   2024-96063   msmarco_v2.1_doc_30_727526048#13_1657957899            0   \n",
       "2237   2024-96063    msmarco_v2.1_doc_42_303001194#16_566169799            0   \n",
       "2238   2024-96063    msmarco_v2.1_doc_25_785358561#0_1506541701            0   \n",
       "2239   2024-96063   msmarco_v2.1_doc_52_1260126505#8_2526623662            3   \n",
       "\n",
       "                                                  topic  \\\n",
       "0     is it dangerous to have wbc over 15,000 withou...   \n",
       "1     is it dangerous to have wbc over 15,000 withou...   \n",
       "2     is it dangerous to have wbc over 15,000 withou...   \n",
       "3     is it dangerous to have wbc over 15,000 withou...   \n",
       "4     is it dangerous to have wbc over 15,000 withou...   \n",
       "...                                                 ...   \n",
       "2235            how using maps can impact your pedagogy   \n",
       "2236            how using maps can impact your pedagogy   \n",
       "2237            how using maps can impact your pedagogy   \n",
       "2238            how using maps can impact your pedagogy   \n",
       "2239            how using maps can impact your pedagogy   \n",
       "\n",
       "                                                    doc  \n",
       "0     Hydrocodone Withdrawal: Symptoms, Timeline, an...  \n",
       "1     Bacteremia Treatment & Management: Medical Car...  \n",
       "2     Neonatal sepsis - Wikipedia Neonatal sepsis\\nN...  \n",
       "3     Cause of Low and High White Blood Cell Count i...  \n",
       "4     Treatment Options Post CLL Diagnosis | Everyda...  \n",
       "...                                                 ...  \n",
       "2235  Intersectional Pedagogy | Denver Intersectiona...  \n",
       "2236  Pedagogy: What Educators Need to Know [Plus: 4...  \n",
       "2237  The Measures of Academic Progress (MAP) Inform...  \n",
       "2238  Putting Pedagogy Principles to Use in Your Cla...  \n",
       "2239    Maps and Map Learning in Social Studies\\nRes...  \n",
       "\n",
       "[2240 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from slt_positional_bias.dataset import generate_merged_data_frame, sort_data_frame, store_df_as_parquet, load_parquet_as_df\n",
    "\n",
    "df = generate_merged_data_frame()\n",
    "\n",
    "df_sorted = sort_data_frame(df, 1, 39)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api.helmholtz-blablador.fz-juelich.de/v1/\"\n",
    "API_KEY = \"\"\n",
    "API_MODEL = \"alias-large\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=API_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbfd2675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2240/2240 [1:53:33<00:00,  3.04s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-09 20:37:54.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mslt_positional_bias.dataset\u001b[0m:\u001b[36mstore_df_as_parquet\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mData frame saved to C:\\Users\\marti\\slt_group_2_positional_bias\\data\\processed\\output_cleaned_df_eval-1-2025-08-09 20h-37m-54s.parquet\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Wie viele Dokumente sollen bereinigt werden?\n",
    "n_to_clean = 2240\n",
    "\n",
    "# Neue Kopie für bearbeitete Texte\n",
    "df_cleaned = df_sorted.copy()\n",
    "\n",
    "# System Prompt\n",
    "system_prompt = (\n",
    "    \"You are a language model specialized in content distillation. \"\n",
    "    \"Your goal is to reduce passages to around 200 tokens while preserving all critical information. \"\n",
    "    \"You must avoid removing any content that could be essential to understanding the topic, its implications, or its technical depth. You should use the same vocabularies used in the original document.\"\n",
    ")\n",
    "\n",
    "# Kürzungsschleife\n",
    "for idx in tqdm(range(n_to_clean)):\n",
    "    topic = df_sorted.iloc[idx]['topic']\n",
    "    original_text = df_sorted.iloc[idx]['doc']\n",
    "    user_prompt = f\"\"\"\n",
    "\n",
    "    Your task is to shorten the passage to approximately 200 tokens while retaining all essential and topic-relevant information. \n",
    "    Preserve technical content, facts, processes, and insights mentioned in the text. \n",
    "    You should use the vocabularies used in the original document and don't add any new information.\n",
    "\n",
    "    Avoid:\n",
    "    - Structural or editorial elements (like tables of contents, section numbers, or headings)\n",
    "    - Redundant or general-purpose filler text\n",
    "\n",
    "    Keep:\n",
    "    - All technical explanations\n",
    "    - Data and findings\n",
    "    - Descriptions of methods and applications\n",
    "\n",
    "    Input passage:\n",
    "    \\\"\\\"\\\"{original_text}\\\"\\\"\\\"\n",
    "\n",
    "    Shortened version (~200 tokens, no critical information lost):\n",
    "    \"\"\".strip()\n",
    "\n",
    "    # LLM Anfrage\n",
    "    response = client.chat.completions.create(\n",
    "        model=API_MODEL,\n",
    "        temperature=0.3,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    raw_output = response.choices[0].message.content.strip()\n",
    "    if \"</think>\" in raw_output.lower():\n",
    "        cleaned_text = raw_output.lower().split(\"</think>\")[-1].strip()\n",
    "    else:\n",
    "        cleaned_text = raw_output\n",
    "    # Gekürzten Text in DataFrame schreiben\n",
    "    df_cleaned.at[idx, 'doc'] = cleaned_text\n",
    "\n",
    "store_df_as_parquet(df_cleaned, \"output_cleaned_df_eval\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6b0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   df_num  avg_tokens  avg_wordcount\n",
      "0       1   66.328571     150.807143\n",
      "1       2   66.675000     154.221429\n",
      "2       3   64.878571     152.175000\n",
      "3       4   64.250000     148.414286\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from slt_positional_bias.dataset import load_parquet_as_df, normalize_and_tokenize\n",
    "\n",
    "def word_count_list(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "def average_token_count(df):\n",
    "    token_counts = df[\"answer\"].apply(lambda x: len(normalize_and_tokenize(str(x))))\n",
    "    return token_counts.mean()\n",
    "\n",
    "dfs = [\n",
    "    load_parquet_as_df(\"LLM-1 - Llama3 405 the best general model and big context size-sample-count-10-1-2025-08-10 00h-18m-01s\"), \n",
    "    load_parquet_as_df(\"LLM-1 - Llama3 405 the best general model and big context size-sample-count-20-1-2025-08-10 14h-40m-19s\"), \n",
    "    load_parquet_as_df(\"LLM-1 - Llama3 405 the best general model and big context size-sample-count-30-1-2025-08-10 16h-54m-56s\"), \n",
    "    load_parquet_as_df(\"LLM-1 - Llama3 405 the best general model and big context size-sample-count-40-1-2025-08-10 18h-46m-08s\")\n",
    "]\n",
    "\n",
    "avg_list = []\n",
    "\n",
    "for i, df in enumerate(dfs, start=1):\n",
    "    avg_tokens = average_token_count(df) \n",
    "    avg_wordcount = df[\"answer\"].apply(lambda x: len(word_count_list(x))).mean()  \n",
    "    avg_list.append({\n",
    "        \"df_num\": i,\n",
    "        \"avg_tokens\": avg_tokens,\n",
    "        \"avg_wordcount\": avg_wordcount\n",
    "    })\n",
    "\n",
    "avg_df = pd.DataFrame(avg_list)\n",
    "\n",
    "print(avg_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6c95fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Having a WBC count over 15,000 without treatment can lead to severe complications such as bleeding, lung injury, or kidney damage. Treatment may include leukapheresis, blood transfusions, and medicines to manage underlying causes. Without treatment, the risk of complications increases. However, the decision to treat should consider symptom status and disease progression. In some cases, observation may be appropriate if no symptoms are present. It is essential to consult a doctor to determine the best course of action.\n",
       "Name: answer, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_parquet_as_df(\"LLM-1 - Llama3 405 the best general model and big context size-sample-count-10-1-2025-08-10 00h-18m-01s\")\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df[\"answer\"].head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
