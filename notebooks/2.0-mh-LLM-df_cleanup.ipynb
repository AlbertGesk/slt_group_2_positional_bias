{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c91305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from slt_positional_bias.dataset import generate_merged_data_frame, sort_data_frame, store_df_as_parquet, load_parquet_as_df\n",
    "\n",
    "df = generate_merged_data_frame()\n",
    "\n",
    "df_sorted = sort_data_frame(df, 4, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api.helmholtz-blablador.fz-juelich.de/v1/\"\n",
    "API_KEY = \"\"\n",
    "API_MODEL = \"alias-large\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=API_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Wie viele Dokumente sollen bereinigt werden?\n",
    "n_to_clean = 1600\n",
    "\n",
    "# Neue Kopie für bearbeitete Texte\n",
    "df_cleaned = df_sorted.copy()\n",
    "\n",
    "# System Prompt\n",
    "system_prompt = (\n",
    "    \"You are a language model specialized in content distillation. \"\n",
    "    \"Your goal is to reduce passages to around 200 tokens while preserving all critical information. \"\n",
    "    \"You must avoid removing any content that could be essential to understanding the topic, its implications, or its technical depth. You should use the same vocabularies used in the original document.\"\n",
    ")\n",
    "\n",
    "# Kürzungsschleife\n",
    "for idx in tqdm(range(n_to_clean)):\n",
    "    topic = df_sorted.iloc[idx]['topic']\n",
    "    original_text = df_sorted.iloc[idx]['doc']\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    You are given a passage from a document. The document is related to the topic: \"{topic}\".\n",
    "\n",
    "    Your task is to shorten the passage to approximately 200 tokens while retaining all essential and topic-relevant information. \n",
    "    Focus on preserving technical content, facts, processes, and insights that directly support or explain the topic. \n",
    "    You should use the of vocabularies used in the original document.\n",
    "\n",
    "    Avoid:\n",
    "    - Structural or editorial elements (like tables of contents, section numbers, or headings)\n",
    "    - Redundant or general-purpose filler text\n",
    "\n",
    "    Keep:\n",
    "    - All technical explanations\n",
    "    - Relevant data or findings\n",
    "    - Descriptions of methods, applications, or implications related to the topic\n",
    "\n",
    "    Input passage:\n",
    "    \\\"\\\"\\\"{original_text}\\\"\\\"\\\"\n",
    "\n",
    "    Shortened version (~200 tokens, no critical information lost):\n",
    "    \"\"\".strip()\n",
    "\n",
    "    # LLM Anfrage\n",
    "    response = client.chat.completions.create(\n",
    "        model=API_MODEL,\n",
    "        temperature=0.3,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    raw_output = response.choices[0].message.content.strip()\n",
    "    if \"</think>\" in raw_output.lower():\n",
    "        cleaned_text = raw_output.lower().split(\"</think>\")[-1].strip()\n",
    "    else:\n",
    "        cleaned_text = raw_output\n",
    "    # Gekürzten Text in DataFrame schreiben\n",
    "    df_cleaned.at[idx, 'doc'] = cleaned_text\n",
    "\n",
    "store_df_as_parquet(df_cleaned, \"output_cleaned_df\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
